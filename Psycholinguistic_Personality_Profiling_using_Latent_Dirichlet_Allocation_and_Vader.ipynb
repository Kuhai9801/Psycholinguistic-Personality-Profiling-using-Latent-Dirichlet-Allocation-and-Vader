{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "OFS8OfoYfh4R"
      }
    },
    {
      "source": [
        "!pip install vaderSentiment"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "XXi1zz5NihOK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "!pip install pyLDAvis==3.4.1"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "4t-dva_uOFGu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "dHF4vyK2eTbp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "!unzip mbti-personality-type-twitter-dataset.zip"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "zgj8Jo0JgpF6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "!mv /mbti-personality-type-twitter-dataset.zip /content/"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "XYVch3f4hgbq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "!pip install nltk gensim pyLDAvis\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "import pandas as pd\n",
        "import re\n",
        "import os\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from gensim import corpora\n",
        "from gensim.models import LdaModel\n",
        "import pyLDAvis\n",
        "import pyLDAvis.gensim_models as gensimvis\n",
        "\n",
        "# Load data using the correct filename with quotes\n",
        "data = pd.read_csv('/content/twitter_MBTI.csv')\n",
        "\n",
        "# Enhanced cleaning with stop word removal and lemmatization\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Add Filipino stop words\n",
        "filipino_stop_words = set(['ako', 'ikaw', 'siya', 'tayo', 'kayo', 'sila',\n",
        "                           'ang', 'ng', 'sa', 'mga', 'ay', 'na', 'at',\n",
        "                           'ni', 'para', 'kay', 'rin', 'din', 'dito',\n",
        "                           'doon', 'kanya', 'kanila'])  # Add more Filipino stop words as needed\n",
        "stop_words.update(filipino_stop_words)\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'http\\S+', '', text)\n",
        "    text = re.sub(r'@\\w+', '', text)\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    text = text.lower()  # Lowercase\n",
        "    tokens = text.split()  # Tokenize\n",
        "    tokens = [lemmatizer.lemmatize(token) for token in tokens\n",
        "              if token not in stop_words and len(token) > 2]  # Lemmatize and remove short words\n",
        "    return tokens\n",
        "\n",
        "data['cleaned_tokens'] = data['text'].apply(clean_text)\n",
        "\n",
        "# Create dictionary and corpus\n",
        "dictionary = corpora.Dictionary(data['cleaned_tokens'])\n",
        "dictionary.filter_extremes(no_below=5, no_above=0.5)  # Filter words appearing in less than 5 documents or more than 50% of documents\n",
        "corpus = [dictionary.doc2bow(text) for text in data['cleaned_tokens']]\n",
        "\n",
        "# Build LDA model\n",
        "num_topics = 3\n",
        "lda_model = LdaModel(corpus=corpus,\n",
        "                        id2word=dictionary,\n",
        "                        num_topics=num_topics,\n",
        "                        passes=15,\n",
        "                        alpha=0.1,\n",
        "                        eta=0.005)\n",
        "\n",
        "# Visualize topics using pyLDAvis\n",
        "vis = gensimvis.prepare(lda_model, corpus, dictionary)\n",
        "pyLDAvis.display(vis)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "ut6RnuZgZtpd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "data.rename(columns={'label': 'type'}, inplace=True)\n",
        "\n",
        "topic_distribution = []\n",
        "for index, row in data.iterrows():\n",
        "    bow = dictionary.doc2bow(row['cleaned_tokens'])\n",
        "    topic_probs = lda_model.get_document_topics(bow)\n",
        "    topic_distribution.append({'type': row['type'], **{f'topic_{i}': prob for i, prob in topic_probs}})\n",
        "\n",
        "topic_mbti_df = pd.DataFrame(topic_distribution).fillna(0)  # Fill missing topics with 0 probability\n",
        "topic_mbti_df = topic_mbti_df.groupby('type').mean()  # Get average topic probabilities for each MBTI type\n",
        "\n",
        "print(topic_mbti_df)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "8sTSD0x9cagH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a heatmap to visualize MBTI type and topic association\n",
        "plt.figure(figsize=(12, 6))  # Adjust figure size as needed\n",
        "sns.heatmap(topic_mbti_df, annot=True, cmap=\"YlGnBu\", fmt=\".3f\")\n",
        "plt.title(\"MBTI Type and Topic Association\")\n",
        "plt.xlabel(\"Topic\")\n",
        "plt.ylabel(\"MBTI Type\")\n",
        "plt.show()"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "QHHQHfnfdAQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "!pip install nltk\n",
        "import nltk\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "\n",
        "analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "data['sentiment'] = data['text'].apply(lambda text: analyzer.polarity_scores(text)['compound'])\n",
        "\n",
        "# Group by MBTI type and calculate average sentiment\n",
        "sentiment_by_mbti = data.groupby('type')['sentiment'].mean()\n",
        "\n",
        "# Print the results\n",
        "print(sentiment_by_mbti)\n",
        "\n",
        "# Visualize using a bar plot\n",
        "import matplotlib.pyplot as plt\n",
        "sentiment_by_mbti.plot(kind='bar', figsize=(10, 6))\n",
        "plt.title('Average Sentiment by MBTI Type using VADER')\n",
        "plt.xlabel('MBTI Type')\n",
        "plt.ylabel('Average Sentiment Score')\n",
        "plt.show()"
      ],
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "MkZwnW8adpye"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}